---
sidebar_position: 2
title: Lesson 2.2 - Sensor Integration and ROS 2 Interfaces
---

# Lesson 2.2: Sensor Integration and ROS 2 Interfaces

**Duration**: ~3 hours | **Pages**: 20 | **Difficulty**: Intermediate

## Learning Objectives

By the end of this lesson, you will:
- ‚úÖ Simulate realistic sensors (camera, depth, LiDAR, IMU)
- ‚úÖ Configure sensor noise and accuracy parameters
- ‚úÖ Subscribe to sensor data from Gazebo
- ‚úÖ Process point clouds and image data in ROS 2
- ‚úÖ Integrate sensor plugins with robot controllers
- ‚úÖ Debug sensor performance and troubleshoot issues

---

## üé• Camera Simulation

### RGB Camera

```xml
<sensor name="front_camera" type="camera">
  <pose>0.2 0 0.1 0 0 0</pose>
  <camera>
    <horizontal_fov>1.2</horizontal_fov>
    <image>
      <width>1280</width>
      <height>720</height>
      <format>R8G8B8</format>
    </image>
    <clip>
      <near>0.01</near>
      <far>100</far>
    </clip>
    <noise>
      <type>gaussian</type>
      <mean>0</mean>
      <stddev>0.01</stddev>
    </noise>
  </camera>
  <always_on>true</always_on>
  <update_rate>30</update_rate>
  <visualize>true</visualize>
</sensor>
```

### Depth Camera (RGB-D)

```xml
<sensor name="depth_camera" type="depth_camera">
  <pose>0.2 0 0.1 0 0 0</pose>
  <camera>
    <horizontal_fov>1.0472</horizontal_fov>
    <image>
      <width>640</width>
      <height>480</height>
    </image>
    <clip>
      <near>0.1</near>
      <far>20</far>
    </clip>
  </camera>
  <always_on>true</always_on>
  <update_rate>30</update_rate>
</sensor>
```

### Subscribing to Camera Data

```python
import rclpy
from sensor_msgs.msg import Image
import cv2
from cv_bridge import CvBridge

class CameraSubscriber(rclpy.node.Node):
    def __init__(self):
        super().__init__('camera_subscriber')
        self.subscription = self.create_subscription(
            Image,
            '/camera/image_raw',
            self.image_callback,
            10
        )
        self.bridge = CvBridge()

    def image_callback(self, msg):
        # Convert ROS Image to OpenCV format
        cv_image = self.bridge.imgmsg_to_cv2(msg, 'bgr8')

        # Process image
        gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 50, 150)

        self.get_logger().info(f'Image received: {cv_image.shape}')

def main():
    rclpy.init()
    subscriber = CameraSubscriber()
    rclpy.spin(subscriber)
    rclpy.shutdown()
```

---

## üì° LiDAR Simulation

### 2D LiDAR (Planar Scanner)

```xml
<sensor name="lidar_2d" type="ray">
  <pose>0 0 0.2 0 0 0</pose>
  <ray>
    <scan>
      <horizontal>
        <samples>720</samples>
        <resolution>1.0</resolution>
        <min_angle>-3.14159</min_angle>
        <max_angle>3.14159</max_angle>
      </horizontal>
    </scan>
    <range>
      <min>0.05</min>
      <max>30</max>
      <resolution>0.015</resolution>
    </range>
    <noise>
      <type>gaussian</type>
      <mean>0</mean>
      <stddev>0.01</stddev>
    </noise>
  </ray>
  <always_on>true</always_on>
  <update_rate>10</update_rate>
</sensor>
```

### Processing LiDAR Data

```python
import numpy as np
from sensor_msgs.msg import LaserScan

class LidarProcessor(rclpy.node.Node):
    def __init__(self):
        super().__init__('lidar_processor')
        self.subscription = self.create_subscription(
            LaserScan,
            '/scan',
            self.scan_callback,
            10
        )

    def scan_callback(self, msg):
        # Convert to numpy array
        ranges = np.array(msg.ranges)

        # Find closest obstacle
        valid_ranges = ranges[ranges > msg.range_min]
        if len(valid_ranges) > 0:
            min_distance = np.min(valid_ranges)
            self.get_logger().info(f'Closest obstacle: {min_distance:.2f}m')
```

---

## üìè IMU Simulation

### Inertial Measurement Unit

```xml
<sensor name="imu" type="imu">
  <pose>0 0 0.1 0 0 0</pose>
  <imu>
    <angular_velocity>
      <x>
        <noise type="gaussian">
          <mean>0</mean>
          <stddev>0.01</stddev>
        </noise>
      </x>
      <y>
        <noise type="gaussian">
          <mean>0</mean>
          <stddev>0.01</stddev>
        </noise>
      </y>
      <z>
        <noise type="gaussian">
          <mean>0</mean>
          <stddev>0.01</stddev>
        </noise>
      </z>
    </angular_velocity>
    <linear_acceleration>
      <x>
        <noise type="gaussian">
          <mean>0</mean>
          <stddev>0.02</stddev>
        </noise>
      </x>
      <y>
        <noise type="gaussian">
          <mean>0</mean>
          <stddev>0.02</stddev>
        </noise>
      </y>
      <z>
        <noise type="gaussian">
          <mean>0</mean>
          <stddev>0.02</stddev>
        </noise>
      </z>
    </linear_acceleration>
  </imu>
  <always_on>true</always_on>
  <update_rate>100</update_rate>
</sensor>
```

### Subscribing to IMU Data

```python
from sensor_msgs.msg import Imu

class IMUSubscriber(rclpy.node.Node):
    def __init__(self):
        super().__init__('imu_subscriber')
        self.subscription = self.create_subscription(
            Imu,
            '/imu',
            self.imu_callback,
            10
        )

    def imu_callback(self, msg):
        # Extract acceleration and angular velocity
        accel = msg.linear_acceleration
        gyro = msg.angular_velocity

        # Estimate orientation (simplified)
        roll = np.arctan2(accel.y, accel.z)
        pitch = np.arctan2(-accel.x, np.sqrt(accel.y**2 + accel.z**2))

        self.get_logger().info(
            f'Roll: {np.degrees(roll):.1f}¬∞, Pitch: {np.degrees(pitch):.1f}¬∞'
        )
```

---

## üìä Sensor Noise Modeling

### Adding Realistic Noise

```xml
<!-- Gaussian noise (normal distribution) -->
<noise>
  <type>gaussian</type>
  <mean>0.0</mean>
  <stddev>0.01</stddev>
</noise>

<!-- Gaussian noise with bias -->
<noise>
  <type>gaussian_quantized</type>
  <mean>0.0</mean>
  <stddev>0.01</stddev>
  <bias_mean>0.1</bias_mean>
  <bias_stddev>0.001</bias_stddev>
  <precision>0.001</precision>
</noise>
```

### Filtering Noisy Sensor Data

```python
from collections import deque
import numpy as np

class MovingAverageFilter:
    def __init__(self, window_size=5):
        self.window_size = window_size
        self.values = deque(maxlen=window_size)

    def filter(self, value):
        self.values.append(value)
        return np.mean(list(self.values))

class KalmanFilter:
    def __init__(self, q=0.01, r=0.1):
        self.q = q  # Process noise
        self.r = r  # Measurement noise
        self.x = 0  # State
        self.p = 1  # Covariance

    def update(self, z):
        # Prediction
        self.p = self.p + self.q

        # Update
        self.k = self.p / (self.p + self.r)  # Kalman gain
        self.x = self.x + self.k * (z - self.x)
        self.p = (1 - self.k) * self.p

        return self.x
```

---

## üîß Common Sensor Issues and Solutions

| Problem | Cause | Solution |
|---------|-------|----------|
| Noisy readings | High stddev | Reduce `<stddev>` or add filter |
| Missing data | Occlusion/dropout | Validate before processing |
| Lag | Low update rate | Increase `<update_rate>` |
| Unphysical values | Sensor saturation | Clip values to valid range |

---

## ‚ú® Best Practices

1. Match sensor specs to real hardware
2. Add realistic noise to improve generalization
3. Filter data before processing
4. Log sensor diagnostics
5. Validate data before control decisions
6. Use multiple redundant sensors for critical tasks

---

**Next**: [Lesson 2.3 - Control and Joint Dynamics](lesson-2-3-control.mdx)
